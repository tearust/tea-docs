# Transaction Consensus Using Time

The TEA Project uses two different types of consensus on its compute layer:

- The consensus used in remote attestation as governed by the hardware security modules of the compute nodes.
- The consensus used to order transactions as governed by the GPS modules of the compute nodes.

The TEA Project uses time as the basis of its consensus to order transactions as reported by the (trusted) GPS modules of the compute nodes. The TEA Project's state machine nodes are in charge of synchronizing the current state between multiple nodes so that the transaction sequence is consistent across all the state machine nodes. We do this by relying on the accurate time provided by the atomic clock of GPS satellites. 

## TEA Project's Algorithm for Txn Consensus 

The design of the TEA Project's compute layer consensus ensures that even if transactions are missing (e.g. the transaction is delayed by network congestion), the ordering of transactions will still be correct. Before we describe the txn consensus algorithm, let's go over some useful terminology.

- A compute node will send its transactions to multiple state maintainer nodes as part of the consensus mechanism. These duplicate recipients are referred to as **replicas**.
- There's a **buffer** period after which reported transactions will be dropped. To ensure that most replicas can be synchronized to a consistent state, the TEA Project’s state machine requires a short waiting queue due to network latency.  Since time is stable in our universe, it follows that each replica can achieve strong consistency using time as a root of trust for consensus. The buffer time is adjustable by the TEA Project and is currently set at 3 seconds. For example, if a node's current clock is at *T*, then any reports of txns with timestamps earlier than *T - 3* seconds will be dropped.
- The foundation of the compute layer's consensus on txn ordering is the trusted timestamp. These are trustable by virtue of the HSM that watch over the GPS modules on the compute node machines.
- A **conveyor belt** is used to order txns within each replica. Transactions can be added but never removed from each replicas conveyor belt.

The TEA Project is able to achieve a reliable ordering of transactions through the following algorithm:

- The compute nodes send **transaction hashes** and **transaction receipts** to multiple state machine nodes, referred to as replicas. Because it takes time to package up a transaction and create its hash, the original transactions don't have timestamps of when they were sent out. The followup receipts have timestamps that show when the original txn hash was sent out.
- Replicas match the hashes of transactions with their followup receipts. Replicas can re-order transactions as long as they remain within the buffer period relative to the now time of the replica's clock.
- Replicas are always broadcasting their latest txns and a decentralized, peer-to-peer sync function between replicas keeps the transactions ordered. The sync function can only add a missing transaction hash to a replica when it's missing on their conveyor compared to other replicas on the network.

The consensus algorithm proceeds as new transactions land on each replica's conveyor belt until eventually everyone ends up with the same state. There might be a question of whether the transactions could ever be out of order across the replicas. But the reported time is recognized under the supervision of trusted hardware and used as the basis for the final ranking of all replicas. There might be a chance that a transaction is reported late (e.g. because of network congestion), but not of there being actual differences in the trusted timestamps across replicas.

## State Maintainer Node RAM Storage

The TEA Project's state machine only needs to store these state change in RAM and not the transaction itself. Since the on-board hardware security modules of the mining nodes allows attestation to be run on them, they can be guaranteed to be trustable and don't need to sync up a historic ledger of all previous transactions. Once all nodes are trustable, any node can get the latest state from a nearby node's RAM. Syncing up to the latest state through reading a nearby node's RAM is a quick process, much quicker than having to reconstruct the entire ledger to get the latest block. 

In the TEA Project:

- Transactions are processed with the resulting state change stored in the RAM memory residing in the enclave of the state machine nodes. 
- Every state maintainer node will have the same copy of the state in their memory, as well as the SQL database instance.
- There's also a persistent backup kept to IPFS but in an encrypted format.

The SQL database instance refers to the GlueSQL database that uses the on-board GPS modules of the state maintainer nodes to update the current state continuously. IPFS is only used to write backups of the current database state. The GlueSQL database can be used by developers the same as they use SQL databases in the cloud computing world.

The TEA Project also offers an eventually consistent CRDT database built on OrbitDB that can be used ad hoc by TApps. This type of DB allows for short-term inconsistencies in the business logic of TApps. The TEA Project uses OrbitDB databases built on top of IPFS that run through our compute layer nodes for these transactions.

CRDT stands for conflict-free replication data type, which allows conflict-free mergers between different replications. There are a couple of benefits for TApp developers to use CRDT databases:

- CRDT is fast as it has no time delay and doesn’t need to wait for others. Allowances are made for new transaction reports which are added non-destructively. This is in contrast to the TEA Project’s strong consistency state machine which must wait a minimum amount of time for confirmation.
- CRDT storage cost is cheap, relying on IPFS for decentralized hard drive storage instead of the more expensive RAM storage.

### References and Further Reading
- An interactive TPM simulator: https://google.github.io/tpm-js/
- The official website of the Trusted Computing Group who's responsible for maintaining the open standards of TPM chips: https://trustedcomputinggroup.org/
- Information on Google Spanner which also uses time as a root of trust for ordering transactions: https://en.wikipedia.org/wiki/Spanner_(database)
- A research article detailing how GPS can be used with TPM to create trustable time synchronization among nodes in a network: https://www.mdpi.com/2076-3417/11/18/8288/htm
